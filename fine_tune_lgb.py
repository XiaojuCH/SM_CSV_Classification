import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from lightgbm import LGBMClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# è¯»å–æ‰€æœ‰æ•°æ®æ–‡ä»¶
data_files = ['DH.csv', 'KD.csv', 'PS10.csv', 'PS10-H.csv', 'QZ.csv', 'YM.csv']
labels = ['DH', 'KD', 'PS10', 'PS10-H', 'QZ', 'YM']

# åŠ è½½æ•°æ®
all_data = []
all_labels = []

for file, label in zip(data_files, labels):
    df = pd.read_csv(file, header=None)
    all_data.append(df.values)
    all_labels.extend([label] * len(df))

X = np.vstack(all_data)
y = np.array(all_labels)

print("="*80)
print("LightGBM ç²¾ç»†è°ƒä¼˜")
print("="*80)
print(f"\næ•°æ®è§„æ¨¡: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
print(f"å½“å‰æœ€ä½³: 81.65%")
print(f"ç›®æ ‡: å°è¯•çªç ´ 82%\n")

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# æµ‹è¯•å¤šç»„å‚æ•°é…ç½®
configs = {
    'å½“å‰é…ç½® (åŸºçº¿)': {
        'n_estimators': 1000,
        'max_depth': 15,
        'learning_rate': 0.1,
        'num_leaves': 80,
        'min_child_samples': 20,
        'subsample': 1.0,
        'colsample_bytree': 1.0,
        'reg_alpha': 0.0,
        'reg_lambda': 0.0
    },

    'é…ç½®1: å¢åŠ æ ‘æ·±åº¦': {
        'n_estimators': 1000,
        'max_depth': 20,           # å¢åŠ æ·±åº¦
        'learning_rate': 0.1,
        'num_leaves': 100,         # ç›¸åº”å¢åŠ å¶å­æ•°
        'min_child_samples': 20,
        'subsample': 1.0,
        'colsample_bytree': 1.0,
        'reg_alpha': 0.0,
        'reg_lambda': 0.0
    },

    'é…ç½®2: æ›´å¤šæ ‘+å°å­¦ä¹ ç‡': {
        'n_estimators': 1500,      # æ›´å¤šæ ‘
        'max_depth': 15,
        'learning_rate': 0.05,     # é™ä½å­¦ä¹ ç‡
        'num_leaves': 80,
        'min_child_samples': 20,
        'subsample': 1.0,
        'colsample_bytree': 1.0,
        'reg_alpha': 0.0,
        'reg_lambda': 0.0
    },

    'é…ç½®3: æ·»åŠ æ­£åˆ™åŒ–': {
        'n_estimators': 1000,
        'max_depth': 15,
        'learning_rate': 0.1,
        'num_leaves': 80,
        'min_child_samples': 20,
        'subsample': 0.8,          # è¡Œé‡‡æ ·
        'colsample_bytree': 0.8,   # åˆ—é‡‡æ ·
        'reg_alpha': 0.1,          # L1æ­£åˆ™åŒ–
        'reg_lambda': 0.1          # L2æ­£åˆ™åŒ–
    },

    'é…ç½®4: æ›´å¤šå¶å­èŠ‚ç‚¹': {
        'n_estimators': 1000,
        'max_depth': 18,
        'learning_rate': 0.08,
        'num_leaves': 120,         # æ›´å¤šå¶å­
        'min_child_samples': 15,   # é™ä½æœ€å°æ ·æœ¬æ•°
        'subsample': 1.0,
        'colsample_bytree': 1.0,
        'reg_alpha': 0.0,
        'reg_lambda': 0.0
    },

    'é…ç½®5: å¹³è¡¡é…ç½®': {
        'n_estimators': 1200,
        'max_depth': 18,
        'learning_rate': 0.07,
        'num_leaves': 100,
        'min_child_samples': 15,
        'subsample': 0.9,
        'colsample_bytree': 0.9,
        'reg_alpha': 0.05,
        'reg_lambda': 0.05
    },

    'é…ç½®6: æ¿€è¿›é…ç½®': {
        'n_estimators': 1500,
        'max_depth': 25,           # å¾ˆæ·±çš„æ ‘
        'learning_rate': 0.05,
        'num_leaves': 150,         # å¾ˆå¤šå¶å­
        'min_child_samples': 10,
        'subsample': 0.85,
        'colsample_bytree': 0.85,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1
    }
}

results = {}

print("å¼€å§‹æµ‹è¯•å„é…ç½®...\n")

for config_name, params in configs.items():
    print(f"{'='*80}")
    print(f"æµ‹è¯•: {config_name}")
    print(f"{'='*80}")

    # æ˜¾ç¤ºå…³é”®å‚æ•°
    print(f"å‚æ•°: n_estimators={params['n_estimators']}, max_depth={params['max_depth']}, "
          f"lr={params['learning_rate']}, num_leaves={params['num_leaves']}")

    # è®­ç»ƒæ¨¡å‹
    model = LGBMClassifier(
        random_state=42,
        n_jobs=-1,
        verbose=-1,
        **params
    )

    model.fit(X_train_scaled, y_train)

    # æµ‹è¯•é›†è¯„ä¼°
    y_pred = model.predict(X_test_scaled)
    test_acc = accuracy_score(y_test, y_pred)

    # äº¤å‰éªŒè¯
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, n_jobs=-1)
    cv_mean = cv_scores.mean()
    cv_std = cv_scores.std()

    results[config_name] = {
        'test_acc': test_acc,
        'cv_mean': cv_mean,
        'cv_std': cv_std,
        'model': model,
        'y_pred': y_pred
    }

    print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    print(f"äº¤å‰éªŒè¯: {cv_mean:.4f} (+/- {cv_std:.4f})")

    # ä¸åŸºçº¿å¯¹æ¯”
    improvement = (test_acc - 0.8165) * 100
    if improvement > 0:
        print(f"âœ… ç›¸æ¯”åŸºçº¿æå‡: +{improvement:.2f}%")
    elif improvement < 0:
        print(f"âŒ ç›¸æ¯”åŸºçº¿ä¸‹é™: {improvement:.2f}%")
    else:
        print(f"â– ä¸åŸºçº¿æŒå¹³")
    print()

# ç»“æœæ±‡æ€»
print("\n" + "="*80)
print("ç»“æœæ±‡æ€»")
print("="*80)

print("\næŒ‰æµ‹è¯•å‡†ç¡®ç‡æ’åº:")
sorted_results = sorted(results.items(), key=lambda x: x[1]['test_acc'], reverse=True)

for i, (config_name, result) in enumerate(sorted_results, 1):
    test_acc = result['test_acc']
    cv_mean = result['cv_mean']
    cv_std = result['cv_std']
    improvement = (test_acc - 0.8165) * 100

    print(f"{i}. {config_name}")
    print(f"   æµ‹è¯•: {test_acc:.4f} ({test_acc*100:.2f}%) | "
          f"äº¤å‰éªŒè¯: {cv_mean:.4f} (Â±{cv_std:.4f}) | "
          f"æå‡: {improvement:+.2f}%")

# æ‰¾å‡ºæœ€ä½³é…ç½®
best_config_name = sorted_results[0][0]
best_result = sorted_results[0][1]
best_acc = best_result['test_acc']

print(f"\n{'='*80}")
print(f"ğŸ† æœ€ä½³é…ç½®: {best_config_name}")
print(f"{'='*80}")
print(f"æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.4f} ({best_acc*100:.2f}%)")
print(f"äº¤å‰éªŒè¯: {best_result['cv_mean']:.4f} (Â±{best_result['cv_std']:.4f})")
print(f"ç›¸æ¯”81.65%æå‡: {(best_acc - 0.8165)*100:+.2f}%")

# ç»˜åˆ¶æœ€ä½³æ¨¡å‹çš„æ··æ·†çŸ©é˜µ
print(f"\nç»˜åˆ¶æœ€ä½³é…ç½®çš„æ··æ·†çŸ©é˜µ...")
y_pred_best = best_result['y_pred']

cm = confusion_matrix(y_test, y_pred_best, labels=labels)
cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

tpr = np.diag(cm) / cm.sum(axis=1) * 100
fnr = 100 - tpr

cm_extended = np.zeros((len(labels), len(labels) + 2))
cm_extended[:, :-2] = cm_percent
cm_extended[:, -2] = tpr
cm_extended[:, -1] = fnr

fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(cm_extended, annot=True, fmt='.1f', cmap='YlOrRd',
            xticklabels=list(labels) + ['TPR', 'FNR'],
            yticklabels=labels,
            cbar_kws={'label': 'ç™¾åˆ†æ¯” (%)'},
            linewidths=0.5, linecolor='white', ax=ax)
plt.title(f'{best_config_name}\nå‡†ç¡®ç‡: {best_acc*100:.2f}%',
          fontsize=13, pad=15)
plt.ylabel('çœŸå®ç±»åˆ«', fontsize=11)
plt.xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('fine_tuned_confusion_matrix.png', dpi=300, bbox_inches='tight')
print("æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ° fine_tuned_confusion_matrix.png")

# è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
print("\n" + "="*80)
print("è¯¦ç»†åˆ†ç±»æŠ¥å‘Š")
print("="*80)
print(classification_report(y_test, y_pred_best, target_names=labels))

# ä¿å­˜æœ€ä½³é…ç½®
print("\n" + "="*80)
print("æœ€ä½³é…ç½®å‚æ•°")
print("="*80)
best_params = configs[best_config_name]
print("\nLGBMClassifier(")
for param, value in best_params.items():
    print(f"    {param}={value},")
print("    random_state=42,")
print("    n_jobs=-1,")
print("    verbose=-1")
print(")")

# ä¿å­˜ç»“æœ
with open('fine_tune_results.txt', 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("LightGBM ç²¾ç»†è°ƒä¼˜ç»“æœ\n")
    f.write("="*80 + "\n\n")

    f.write(f"åŸºçº¿å‡†ç¡®ç‡: 81.65%\n")
    f.write(f"æœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.2f}%\n")
    f.write(f"æå‡å¹…åº¦: {(best_acc - 0.8165)*100:+.2f}%\n\n")

    f.write("æ‰€æœ‰é…ç½®ç»“æœ:\n")
    f.write("-"*80 + "\n")
    for i, (config_name, result) in enumerate(sorted_results, 1):
        f.write(f"{i}. {config_name}\n")
        f.write(f"   æµ‹è¯•: {result['test_acc']*100:.2f}% | ")
        f.write(f"äº¤å‰éªŒè¯: {result['cv_mean']*100:.2f}% (Â±{result['cv_std']:.4f})\n")

    f.write(f"\næœ€ä½³é…ç½®: {best_config_name}\n")
    f.write("-"*80 + "\n")
    for param, value in best_params.items():
        f.write(f"{param}: {value}\n")

print("\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° fine_tune_results.txt")
